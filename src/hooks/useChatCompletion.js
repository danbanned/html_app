import { useMutation } from "@tanstack/react-query";

/**
 * üß† useChatCompletion
 * Handles communication with the backend AI service.
 * Automatically normalizes responses and provides clear fallbacks if the AI returns nothing.
 */
export function useChatCompletion() {
  // üåç Use deployment URL or local dev server
  const API_BASE = import.meta.env.VITE_API_BASE_URL || "http://localhost:5000";

  return useMutation({
    mutationFn: async (payload) => {
      console.log("üì§ Sending chat payload (useChatCompletion):", payload);

      try {
        const response = await fetch(`${API_BASE}/api/chat`, {
          method: "POST",
          headers: { "Content-Type": "application/json" },
          body: JSON.stringify(payload),
        });

        if (!response.ok) {
          const text = await response.text();
          console.error("‚ùå Backend HTTP error:", text);
          throw new Error(text || "Assistant unavailable");
        }

        const data = await response.json();
        console.log("ü§ñ Raw AI response received:", data);

        // üß© Sanity check ‚Äî detect totally empty or malformed responses
        if (!data || Object.keys(data).length === 0) {
          console.warn("‚ö†Ô∏è Backend returned an empty object ‚Äî no AI content.");
          return {
            type: "error",
            content: "‚ö†Ô∏è AI returned no usable content.",
            imagePrompt: null,
            error: "Empty response from backend.",
          };
        }

        // üß† Normalize based on mode
        let content =
          data.content ||
          data.reply ||
          data.description ||
          data.text ||
          data.output ||
          null;

        // üß© Improve safety ‚Äî detect AI fallback phrases
        if (
          !content ||
          content.trim().length === 0 ||
          /no response/i.test(content)
        ) {
          content =
            "ü§î The AI didn't respond with meaningful text. Try again or adjust your prompt.";
        }

        const normalized = {
          type: ["storyContinuation", "contextualAssistant", "storyCoach"].includes(
            payload.mode
          )
            ? "chat"
            : "metadata",
          content,
          description: data.description || "",
          tags: data.tags || [],
          imagePrompt:
            data.imagePrompt ||
            (payload.bookContext
              ? `Scene from "${payload.bookContext.title}" ‚Äî ${
                  payload.bookContext.description || "No description"
                }`
              : null),
        };

        console.log("‚úÖ Normalized AI output:", normalized);
        return normalized;
      } catch (err) {
        console.error("üí• AI request failed:", err);

        // ü©π Graceful fallback
        return {
          type: "error",
          content:
            "‚ö†Ô∏è The AI assistant could not generate a response. Check your internet or server connection.",
          imagePrompt: null,
          error: err.message || "Unknown error",
        };
      }
    },
  });
}
